{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from meassures import get_meassure\n",
    "from meassures import get_sensitive\n",
    "from meassures import get_specificity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>on_thyroxine</th>\n",
       "      <th>query_on_thyroxine</th>\n",
       "      <th>on_antithyroid_medication</th>\n",
       "      <th>thyroid_surgery</th>\n",
       "      <th>query_hypothyroid</th>\n",
       "      <th>query_hyperthyroid</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>sick</th>\n",
       "      <th>tumor</th>\n",
       "      <th>lithium</th>\n",
       "      <th>...</th>\n",
       "      <th>T4U_measured</th>\n",
       "      <th>FTI_measured</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>TSH</th>\n",
       "      <th>T3</th>\n",
       "      <th>TT4</th>\n",
       "      <th>T4U</th>\n",
       "      <th>FTI</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>165.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   on_thyroxine  query_on_thyroxine  on_antithyroid_medication  \\\n",
       "0             0                   0                          0   \n",
       "1             0                   0                          0   \n",
       "2             0                   0                          0   \n",
       "3             0                   0                          0   \n",
       "4             0                   0                          0   \n",
       "\n",
       "   thyroid_surgery  query_hypothyroid  query_hyperthyroid  pregnant  sick  \\\n",
       "0                0                  0                   0         0     0   \n",
       "1                0                  0                   0         0     0   \n",
       "2                0                  0                   0         0     0   \n",
       "3                0                  0                   0         0     0   \n",
       "4                0                  0                   0         0     0   \n",
       "\n",
       "   tumor  lithium   ...     T4U_measured  FTI_measured  age  sex  TSH   T3  \\\n",
       "0      0        0   ...                1             1   80    1  1.4  0.8   \n",
       "1      0        0   ...                1             1   74    0  0.0  0.7   \n",
       "2      0        0   ...                1             1   32    0  1.4  1.1   \n",
       "3      0        0   ...                1             1   42    0  2.3  1.1   \n",
       "4      0        0   ...                1             1   89    1  0.8  0.8   \n",
       "\n",
       "     TT4   T4U    FTI  classes  \n",
       "0  105.0  0.88  120.0        1  \n",
       "1   98.0  0.81  121.0        1  \n",
       "2  121.0  1.11  109.0        1  \n",
       "3   93.0  0.73  127.0        1  \n",
       "4  111.0  0.68  165.0        1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se cargan los datos\n",
    "data = pd.read_csv('full_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los nuevos conjuntos de clases: Counter({0: 380, 1: 380})\n"
     ]
    }
   ],
   "source": [
    "# Sobre y sub muestreo\n",
    "\n",
    "# Se separan los datos en conjuntos por clase\n",
    "major_class = data[data.classes == 0]\n",
    "minor_class = data[data.classes == 1]\n",
    "\n",
    "# Se hace un sobremuestreo sobre la clase minoritaria\n",
    "minor_class_upsampled = resample(minor_class, replace=True, n_samples=380, random_state=42)\n",
    "\n",
    "# Se unen los conjuntos en un nuevo conjunto único de clases\n",
    "data_new = pd.concat([major_class, minor_class_upsampled])\n",
    "\n",
    "# Se separan características de etiquetas\n",
    "features = data_new.iloc[:, 0:-1]\n",
    "target = data_new.iloc[:, -1]\n",
    "\n",
    "# Se hace sub muestreo de conjunto mayoritario\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "features, target = rus.fit_resample(features, target)\n",
    "print('Tamaño de los nuevos conjuntos de clases: {0}'.format(Counter(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [0.73008277 0.13584966 0.07637629]\n",
      "[[ 6.64502672e-04  8.67051428e-06  1.08290465e-04  3.61655605e-04\n",
      "  -1.43533672e-04  2.47721001e-04  2.05906722e-05 -1.59899289e-04\n",
      "  -1.38659130e-05  0.00000000e+00  2.32739239e-05 -3.55526898e-04\n",
      "  -6.14162081e-04 -3.29916554e-04 -3.29916554e-04 -3.29916554e-04\n",
      "  -9.95433856e-04 -7.47367674e-04 -1.05582613e-01  6.64520657e-03\n",
      "   6.91430986e-01  3.32942169e-04  7.14652476e-01]\n",
      " [-1.38752592e-03  1.59114388e-04 -3.93985402e-04  3.11332170e-04\n",
      "  -1.04238811e-03 -9.64105660e-04 -1.12338983e-03  1.97416617e-03\n",
      "  -4.31437242e-05  0.00000000e+00 -8.89744455e-04  2.70249630e-03\n",
      "   3.96017885e-03  1.54603878e-03  1.54603878e-03  1.54603878e-03\n",
      "   7.93251577e-01  9.12557922e-04 -7.81584925e-02 -2.17710796e-02\n",
      "  -4.38732598e-01 -6.25389302e-03  4.14249491e-01]\n",
      " [-5.73132156e-04  4.61226886e-04  1.50478031e-04 -1.74992453e-04\n",
      "  -2.66810290e-04  9.66147359e-04 -5.47846116e-04 -3.40029547e-04\n",
      "   6.93841749e-04 -0.00000000e+00 -6.42887191e-04 -6.23746898e-04\n",
      "   3.35047752e-04  4.29792035e-04  4.29792035e-04  4.29792035e-04\n",
      "  -6.08136296e-01  5.26966553e-03 -6.01055983e-02 -3.29763193e-03\n",
      "  -5.73651269e-01 -7.74389573e-03  5.45324864e-01]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(.93)\n",
    "pca = pca.fit(features)\n",
    "print(\"Explained Variance: {0}\".format(pca.explained_variance_ratio_))\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Número de componentes: 1\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Entrenamiento: 0.9986847622090006 +- 0.0010840902058346005\n",
      "Validación: 0.9618055555555557 +- 0.01486440879342429\n",
      "-------------------------------------\n",
      "Sensibilidad: 0.9047619047619048, Especificidad: 0.9523809523809523\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Número de componentes: 2\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Entrenamiento: 0.9986847622090006 +- 0.0010840902058346005\n",
      "Validación: 0.9618055555555557 +- 0.01486440879342429\n",
      "-------------------------------------\n",
      "Sensibilidad: 0.9047619047619048, Especificidad: 0.9523809523809523\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Número de componentes: 5\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Entrenamiento: 0.9986847622090006 +- 0.0010840902058346005\n",
      "Validación: 0.9618055555555557 +- 0.01486440879342429\n",
      "-------------------------------------\n",
      "Sensibilidad: 0.9047619047619048, Especificidad: 0.9523809523809523\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Número de componentes: 10\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Entrenamiento: 0.9986847622090006 +- 0.0010840902058346005\n",
      "Validación: 0.9618055555555557 +- 0.01486440879342429\n",
      "-------------------------------------\n",
      "Sensibilidad: 0.9047619047619048, Especificidad: 0.9523809523809523\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for n_component in [1, 2, 5, 10]:\n",
    "    pca = PCA(n_components=n_component)\n",
    "    new_features = pca.fit_transform(features)\n",
    "    fold = 6\n",
    "    np.random.seed(12345)\n",
    "    efficiency_train = np.zeros(fold)\n",
    "    efficiency_validation = np.zeros(fold)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=fold, random_state=None, shuffle=False)\n",
    "\n",
    "    j = 0\n",
    "    for train, test in skf.split(new_features, target):\n",
    "        x_train = features[train, :]\n",
    "        y_train = target[train]\n",
    "        x_test = features[test, :]\n",
    "        y_test = target[test]\n",
    "\n",
    "        # Random Forest model\n",
    "        model = RandomForestClassifier(n_estimators=20)\n",
    "        model = model.fit(x_train, y_train)\n",
    "\n",
    "        # Realizamos predicciones\n",
    "        y_est_train = model.predict(x_train)\n",
    "        y_est_test = model.predict(x_test)\n",
    "\n",
    "        # Evaluamos las predicciones del modelo con los datos de test\n",
    "        efficiency_train[j] = np.mean(y_est_train == y_train)\n",
    "        efficiency_validation[j] = np.mean(y_est_test == y_test)\n",
    "        \n",
    "        # Medimos Sensibilidad y Especificidad\n",
    "        tp, fp, tn, fn = get_meassure(y_test, y_est_test)\n",
    "        sensitive = get_sensitive(tp, fn)\n",
    "        specificity = get_specificity(tn, fp)\n",
    "        \n",
    "        j += 1\n",
    "    \n",
    "    print('-------------------------------------')\n",
    "    print('Número de componentes: {0}'.format(n_component))\n",
    "    print('-------------------------------------')\n",
    "    print('-------------------------------------')\n",
    "    print('Entrenamiento: {0} +- {1}'.format(str(np.mean(efficiency_train)), str(np.std(efficiency_train))))\n",
    "    print('Validación: {0} +- {1}'.format(str(np.mean(efficiency_validation)), str(np.std(efficiency_validation))))\n",
    "    print('-------------------------------------')\n",
    "    print('Sensibilidad: {0}, Especificidad: {1}'.format(sensitive, specificity))\n",
    "    print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Número de componentes: 1\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Entrenamiento: 0.9493142655587024 +- 0.015305208096104006\n",
      "Validación: 0.9078865141857267 +- 0.006798162106472928\n",
      "-------------------------------------\n",
      "Sensibilidad: 0.9285714285714286, Especificidad: 0.8809523809523809\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Número de componentes: 2\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Entrenamiento: 0.9493142655587024 +- 0.015305208096104006\n",
      "Validación: 0.9078865141857267 +- 0.006798162106472928\n",
      "-------------------------------------\n",
      "Sensibilidad: 0.9285714285714286, Especificidad: 0.8809523809523809\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Número de componentes: 5\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Entrenamiento: 0.9493142655587024 +- 0.015305208096104006\n",
      "Validación: 0.9078865141857267 +- 0.006798162106472928\n",
      "-------------------------------------\n",
      "Sensibilidad: 0.9285714285714286, Especificidad: 0.8809523809523809\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Número de componentes: 10\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Entrenamiento: 0.9493142655587024 +- 0.015305208096104006\n",
      "Validación: 0.9078865141857267 +- 0.006798162106472928\n",
      "-------------------------------------\n",
      "Sensibilidad: 0.9285714285714286, Especificidad: 0.8809523809523809\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for n_component in [1, 2, 5, 10]:\n",
    "    pca = PCA(n_components=n_component)\n",
    "    new_features = pca.fit_transform(features)\n",
    "    fold = 3\n",
    "    np.random.seed(12345)\n",
    "    efficiency_train = np.zeros(fold)\n",
    "    efficiency_validation = np.zeros(fold)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=fold, random_state=None, shuffle=False)\n",
    "\n",
    "    j = 0\n",
    "    for train, test in skf.split(new_features, target):\n",
    "        x_train = features[train, :]\n",
    "        y_train = target[train]\n",
    "        x_test = features[test, :]\n",
    "        y_test = target[test]\n",
    "\n",
    "        # ANN model\n",
    "        model = MLPClassifier(hidden_layer_sizes=(20, 20), activation='logistic', max_iter=500)\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Realizamos predicciones\n",
    "        y_est_train = model.predict(x_train)\n",
    "        y_est_test = model.predict(x_test)\n",
    "\n",
    "        # Evaluamos las predicciones del modelo con los datos de test\n",
    "        efficiency_train[j] = np.mean(y_est_train == y_train)\n",
    "        efficiency_validation[j] = np.mean(y_est_test == y_test)\n",
    "        \n",
    "        # Medimos Sensibilidad y Especificidad\n",
    "        tp, fp, tn, fn = get_meassure(y_test, y_est_test)\n",
    "        sensitive = get_sensitive(tp, fn)\n",
    "        specificity = get_specificity(tn, fp)\n",
    "        \n",
    "        j += 1\n",
    "\n",
    "    \n",
    "    print('-------------------------------------')\n",
    "    print('Número de componentes: {0}'.format(n_component))\n",
    "    print('-------------------------------------')\n",
    "    print('-------------------------------------')\n",
    "    print('Entrenamiento: {0} +- {1}'.format(str(np.mean(efficiency_train)), str(np.std(efficiency_train))))\n",
    "    print('Validación: {0} +- {1}'.format(str(np.mean(efficiency_validation)), str(np.std(efficiency_validation))))\n",
    "    print('-------------------------------------')\n",
    "    print('Sensibilidad: {0}, Especificidad: {1}'.format(sensitive, specificity))\n",
    "    print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Número de componentes: 1\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Entrenamiento: 0.8681609298672951 +- 0.007625508792025321\n",
      "Validación: 0.863095238095238 +- 0.03898611779252276\n",
      "% de Vectores de Soporte = 0.556317300909103\n",
      "-------------------------------------\n",
      "Sensibilidad: 0.9365079365079365, Especificidad: 0.7777777777777778\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Número de componentes: 2\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Entrenamiento: 0.8681609298672951 +- 0.007625508792025321\n",
      "Validación: 0.863095238095238 +- 0.03898611779252276\n",
      "% de Vectores de Soporte = 0.556317300909103\n",
      "-------------------------------------\n",
      "Sensibilidad: 0.9365079365079365, Especificidad: 0.7777777777777778\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Número de componentes: 5\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Entrenamiento: 0.8681609298672951 +- 0.007625508792025321\n",
      "Validación: 0.863095238095238 +- 0.03898611779252276\n",
      "% de Vectores de Soporte = 0.556317300909103\n",
      "-------------------------------------\n",
      "Sensibilidad: 0.9365079365079365, Especificidad: 0.7777777777777778\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Número de componentes: 10\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Entrenamiento: 0.8681609298672951 +- 0.007625508792025321\n",
      "Validación: 0.863095238095238 +- 0.03898611779252276\n",
      "% de Vectores de Soporte = 0.556317300909103\n",
      "-------------------------------------\n",
      "Sensibilidad: 0.9365079365079365, Especificidad: 0.7777777777777778\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for n_component in [1, 2, 5, 10]:\n",
    "    pca = PCA(n_components=n_component)\n",
    "    new_features = pca.fit_transform(features)\n",
    "    fold = 6\n",
    "    np.random.seed(12345)\n",
    "    efficiency_train = np.zeros(fold)\n",
    "    efficiency_validation = np.zeros(fold)\n",
    "    support_vectors_percent = np.zeros(fold)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=fold, random_state=None, shuffle=False)\n",
    "\n",
    "    j = 0\n",
    "    for train, test in skf.split(new_features, target):\n",
    "        x_train = features[train, :]\n",
    "        y_train = target[train]\n",
    "        x_test = features[test, :]\n",
    "        y_test = target[test]\n",
    "\n",
    "        # Random Forest model\n",
    "        model = SVC(gamma=1, C=0.01, kernel='linear', decision_function_shape='ovo')\n",
    "        model = model.fit(x_train, y_train)\n",
    "\n",
    "        # Realizamos predicciones\n",
    "        y_est_train = model.predict(x_train)\n",
    "        y_est_test = model.predict(x_test)\n",
    "\n",
    "        # Evaluamos las predicciones del modelo con los datos de test\n",
    "        efficiency_train[j] = np.mean(y_est_train.ravel() == y_train.ravel())\n",
    "        efficiency_validation[j] = np.mean(y_est_test.ravel() == y_test.ravel())\n",
    "        support_vectors_percent[j] = len(model.support_vectors_) / len(x_train)\n",
    "        \n",
    "        # Medimos Sensibilidad y Especificidad\n",
    "        tp, fp, tn, fn = get_meassure(y_test, y_est_test)\n",
    "        sensitive = get_sensitive(tp, fn)\n",
    "        specificity = get_specificity(tn, fp)\n",
    "        \n",
    "        j += 1\n",
    "    \n",
    "    print('-------------------------------------')\n",
    "    print('Número de componentes: {0}'.format(n_component))\n",
    "    print('-------------------------------------')\n",
    "    print('-------------------------------------')\n",
    "    print('Entrenamiento: {0} +- {1}'.format(str(np.mean(efficiency_train)), str(np.std(efficiency_train))))\n",
    "    print('Validación: {0} +- {1}'.format(str(np.mean(efficiency_validation)), str(np.std(efficiency_validation))))\n",
    "    print('% de Vectores de Soporte = {0}'.format(np.mean(support_vectors_percent))) \n",
    "    print('-------------------------------------')\n",
    "    print('Sensibilidad: {0}, Especificidad: {1}'.format(sensitive, specificity))\n",
    "    print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
